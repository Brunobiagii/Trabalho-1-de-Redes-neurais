{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQEv-uVrYmal"
      },
      "outputs": [],
      "source": [
        "%env CUDA_LAUNCH_BLOCKING=1\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import timm\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from torch import optim\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIbrq4emrQ2K"
      },
      "source": [
        "Carrega o dataset e o divide em: treino, teste e validação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1csgW13hL4bk"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"cifar100\")\n",
        "dataset2 = load_dataset(\"cifar100\")\n",
        "\n",
        "split = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
        "split2 = dataset2[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
        "\n",
        "dataset = DatasetDict({\"train\": split[\"train\"], \"val\": split[\"test\"], \"test\": dataset[\"test\"]})\n",
        "dataset2 = DatasetDict({\"train\": split2[\"train\"], \"val\": split2[\"test\"], \"test\": dataset2[\"test\"]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p0sB4zGrlZZ"
      },
      "source": [
        "Aplica as transformações e argumentações no datase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSWnerjuZOW0"
      },
      "outputs": [],
      "source": [
        "transform_224 = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqXfkiUbZfl-"
      },
      "outputs": [],
      "source": [
        "def transform_batch(example_batch):\n",
        "    imgs = [transform_224(img.convert(\"RGB\")) for img in example_batch[\"img\"]]\n",
        "    example_batch[\"pixel_values\"] = torch.stack(imgs)\n",
        "    example_batch[\"labelsc\"] = example_batch[\"fine_label\"]\n",
        "    example_batch[\"labelssc\"] = example_batch[\"coarse_label\"]\n",
        "    del example_batch[\"img\"]\n",
        "    return example_batch\n",
        "\n",
        "dataset[\"train\"].set_transform(transform_batch)\n",
        "dataset[\"val\"].set_transform(transform_batch)\n",
        "dataset[\"test\"].set_transform(transform_batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "map_20_to_10 = {\n",
        "    0:0, 1:0,\n",
        "    2:1, 3:1,\n",
        "    4:2, 5:2,\n",
        "    6:3, 7:3,\n",
        "    8:4, 9:4,\n",
        "    10:5, 11:5,\n",
        "    12:6, 13:6,\n",
        "    14:7, 15:7,\n",
        "    16:8, 17:8,\n",
        "    18:9, 19:9,\n",
        "}\n",
        "\n",
        "def map_coarse_tensor(tensor20):\n",
        "    mapped = tensor20.cpu().numpy()\n",
        "    mapped = [map_20_to_10[int(x)] for x in mapped]\n",
        "    return torch.tensor(mapped, dtype=torch.long)"
      ],
      "metadata": {
        "id": "X4GtYxIp_c5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_batch2(example_batch):\n",
        "    imgs = [transform_224(img.convert(\"RGB\")) for img in example_batch[\"img\"]]\n",
        "    example_batch[\"pixel_values\"] = torch.stack(imgs)\n",
        "    example_batch[\"labelsc\"] = example_batch[\"fine_label\"]\n",
        "    example_batch[\"labelssc\"] = map_coarse_tensor(torch.tensor(example_batch[\"coarse_label\"], dtype=torch.long))\n",
        "    del example_batch[\"img\"]\n",
        "    return example_batch\n",
        "\n",
        "dataset2[\"train\"].set_transform(transform_batch2)\n",
        "dataset2[\"val\"].set_transform(transform_batch2)\n",
        "dataset2[\"test\"].set_transform(transform_batch2)"
      ],
      "metadata": {
        "id": "f6-6nvFYliVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FidBDT30alJQ"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset[\"train\"], batch_size=128, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(dataset[\"val\"], batch_size=128, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(dataset[\"test\"], batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "train_loader2 = DataLoader(dataset2[\"train\"], batch_size=128, shuffle=True, num_workers=2)\n",
        "val_loader2 = DataLoader(dataset2[\"val\"], batch_size=128, shuffle=False, num_workers=2)\n",
        "test_loader2 = DataLoader(dataset2[\"test\"], batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_k23GioFvvF"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgAaSMohrruF"
      },
      "source": [
        "modelo 100 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MN4aR7mLdOHo"
      },
      "outputs": [],
      "source": [
        "model = timm.create_model('mobilenetv3_small_100', pretrained=True, num_classes=100)\n",
        "model.to(device)\n",
        "\n",
        "loss_train = []\n",
        "loss_eval  = []\n",
        "patience_time = 15\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "opt = optim.AdamW(model.parameters(),lr=0.01)\n",
        "epochs = 100\n",
        "epoch = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh4UDSTwvrJs"
      },
      "source": [
        "Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzBlyizHdeDm"
      },
      "outputs": [],
      "source": [
        "stop = False\n",
        "lowest_loss_eval = 10000\n",
        "last_best_result = 0\n",
        "\n",
        "while (not stop):\n",
        "    model.train()\n",
        "    lloss = []\n",
        "    for batch in train_loader:\n",
        "        images = batch[\"pixel_values\"].to(device)\n",
        "        labels = batch[\"labelsc\"].long().to(device)\n",
        "        pred = model(images)\n",
        "        closs = criterion(pred,labels)\n",
        "        closs.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        lloss.append(closs.item())\n",
        "    loss_train.append(np.mean(lloss))\n",
        "    lloss = []\n",
        "    model.eval()\n",
        "    lres = []\n",
        "    lbtrue = []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            images = batch[\"pixel_values\"].to(device)\n",
        "            labels = batch[\"labelsc\"].long().to(device)\n",
        "\n",
        "            pred = model(images)\n",
        "            closs = criterion(pred,labels)\n",
        "            lloss.append(closs.item())\n",
        "            res  = pred.argmax(dim=1).tolist()\n",
        "            lres += res\n",
        "            lbtrue += labels.cpu()\n",
        "        avg_loss_eval = np.mean(lloss)\n",
        "        loss_eval.append(avg_loss_eval)\n",
        "        if avg_loss_eval < lowest_loss_eval:\n",
        "            lowest_loss_eval = avg_loss_eval\n",
        "            last_best_result = 0\n",
        "            print(\"Best model found! saving...\")\n",
        "            actual_state = {'optim':opt.state_dict(),'model':model.state_dict(),'epoch':epoch,'loss_train':loss_train,'loss_eval':loss_eval}\n",
        "            torch.save(actual_state,'best_modelc.pth')\n",
        "        last_best_result += 1\n",
        "        if last_best_result > patience_time:\n",
        "            stop = True\n",
        "        print(\"epoch %d loss_train %4.3f loss_eval %4.3f last_best %d\"%(epoch,loss_train[-1],loss_eval[-1],last_best_result))\n",
        "        epoch += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW7OafpXtC_h"
      },
      "source": [
        "classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nv1uMXvyozDI"
      },
      "outputs": [],
      "source": [
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        images = batch[\"pixel_values\"].to(device)\n",
        "        labels = batch[\"labelsc\"].to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "print(classification_report(all_labels, all_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdBtLYRArzfT"
      },
      "source": [
        "modelo 20 super-classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4OqQ9fcgHbN"
      },
      "outputs": [],
      "source": [
        "model = timm.create_model('mobilenetv3_small_100', pretrained=True, num_classes=20)\n",
        "model.to(device)\n",
        "\n",
        "loss_train = []\n",
        "loss_eval  = []\n",
        "patience_time = 15\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "opt = optim.AdamW(model.parameters(),lr=0.01)\n",
        "epochs = 100\n",
        "epoch = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XYgi4ZVtHrA"
      },
      "source": [
        "Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "son1kAPtgDlN"
      },
      "outputs": [],
      "source": [
        "stop = False\n",
        "lowest_loss_eval = 10000\n",
        "last_best_result = 0\n",
        "\n",
        "while (not stop):\n",
        "    model.train()\n",
        "    lloss = []\n",
        "    for batch in train_loader:\n",
        "        images = batch[\"pixel_values\"].to(device)\n",
        "        labels = batch[\"labelssc\"].long().to(device)\n",
        "        pred = model(images)\n",
        "        closs = criterion(pred,labels)\n",
        "        closs.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        lloss.append(closs.item())\n",
        "    loss_train.append(np.mean(lloss))\n",
        "    lloss = []\n",
        "    model.eval()\n",
        "    lres = []\n",
        "    lbtrue = []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            images = batch[\"pixel_values\"].to(device)\n",
        "            labels = batch[\"labelssc\"].long().to(device)\n",
        "\n",
        "            pred = model(images)\n",
        "            closs = criterion(pred,labels)\n",
        "            lloss.append(closs.item())\n",
        "            res  = pred.argmax(dim=1).tolist()\n",
        "            lres += res\n",
        "            lbtrue += labels.cpu()\n",
        "        avg_loss_eval = np.mean(lloss)\n",
        "        loss_eval.append(avg_loss_eval)\n",
        "        if avg_loss_eval < lowest_loss_eval:\n",
        "            lowest_loss_eval = avg_loss_eval\n",
        "            last_best_result = 0\n",
        "            print(\"Best model found! saving...\")\n",
        "            actual_state = {'optim':opt.state_dict(),'model':model.state_dict(),'epoch':epoch,'loss_train':loss_train,'loss_eval':loss_eval}\n",
        "            torch.save(actual_state,'best_modelsc.pth')\n",
        "        last_best_result += 1\n",
        "        if last_best_result > patience_time:\n",
        "            stop = True\n",
        "        print(\"epoch %d loss_train %4.3f loss_eval %4.3f last_best %d\"%(epoch,loss_train[-1],loss_eval[-1],last_best_result))\n",
        "        epoch += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7TNkqPstKxv"
      },
      "source": [
        "classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6t0OvCnpphb3"
      },
      "outputs": [],
      "source": [
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        images = batch[\"pixel_values\"].to(device)\n",
        "        labels = batch[\"labelssc\"].to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "print(classification_report(all_labels, all_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoLEx1_Zr3pC"
      },
      "source": [
        "modelo multihead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLIJ88H7hoBg"
      },
      "outputs": [],
      "source": [
        "class MultiHeadMobileNetV3(nn.Module):\n",
        "    def __init__(self, pretrained=True, num_classes_fine=100, num_classes_coarse=10):\n",
        "        super().__init__()\n",
        "\n",
        "        base_model = timm.create_model(\"mobilenetv3_small_100\", pretrained=True, num_classes=0)\n",
        "\n",
        "        self.backbone = base_model\n",
        "\n",
        "\n",
        "        in_features = 1024\n",
        "        self.head_fine = nn.Linear(in_features, num_classes_fine)\n",
        "        self.head_coarse = nn.Linear(in_features, num_classes_coarse)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.backbone(x)\n",
        "        out_fine = self.head_fine(feats)\n",
        "        out_coarse = self.head_coarse(feats)\n",
        "        return out_fine, out_coarse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_nJCOy6j90N"
      },
      "outputs": [],
      "source": [
        "model = MultiHeadMobileNetV3()\n",
        "model.to(device)\n",
        "\n",
        "loss_train = []\n",
        "loss_eval  = []\n",
        "patience_time = 15\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "opt = optim.AdamW(model.parameters(),lr=0.01)\n",
        "epochs = 100\n",
        "epoch = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxIMmGKev0LB"
      },
      "source": [
        "Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiMaQmy5kCt5"
      },
      "outputs": [],
      "source": [
        "stop = False\n",
        "lowest_loss_eval = 10000\n",
        "last_best_result = 0\n",
        "\n",
        "while (not stop):\n",
        "    model.train()\n",
        "    lloss = []\n",
        "    for batch in train_loader2:\n",
        "        images = batch[\"pixel_values\"].to(device)\n",
        "        labels_fine = batch[\"labelsc\"].long().to(device)\n",
        "        labels_coarse = batch[\"labelssc\"].long().to(device)\n",
        "        pred_fine, pred_coarse = model(images)\n",
        "        loss_fine = criterion(pred_fine, labels_fine)\n",
        "        loss_coarse = criterion(pred_coarse, labels_coarse)\n",
        "        loss = 0.7 * loss_fine + 0.3 * loss_coarse\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        lloss.append(loss.item())\n",
        "    loss_train.append(np.mean(lloss))\n",
        "    lloss = []\n",
        "    model.eval()\n",
        "    lresf = []\n",
        "    lresc = []\n",
        "    lbtruef = []\n",
        "    lbtruec = []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader2:\n",
        "            images = batch[\"pixel_values\"].to(device)\n",
        "            labels_fine = batch[\"labelsc\"].long().to(device)\n",
        "            labels_coarse = batch[\"labelssc\"].long().to(device)\n",
        "            if labels_fine.min() < 0 or labels_fine.max() >= 100:\n",
        "                print(\"Label fine fora do range:\", labels_fine.min().item(), labels_fine.max().item())\n",
        "            if labels_coarse.min() < 0 or labels_coarse.max() >= 10:\n",
        "                print(\"Label coarse fora do range:\", labels_coarse.min().item(), labels_coarse.max().item())\n",
        "            pred_fine, pred_coarse = model(images)\n",
        "            loss_fine = criterion(pred_fine, labels_fine)\n",
        "            loss_coarse = criterion(pred_coarse, labels_coarse)\n",
        "            loss = 0.7 * loss_fine + 0.3 * loss_coarse\n",
        "            lloss.append(loss.item())\n",
        "            res  = pred_fine.argmax(dim=1).tolist()\n",
        "            lresf += res\n",
        "            res  = pred_coarse.argmax(dim=1).tolist()\n",
        "            lresc += res\n",
        "            lbtruef += labels_fine.cpu().tolist()\n",
        "            lbtruec += labels_coarse.cpu().tolist()\n",
        "\n",
        "        avg_loss_eval = np.mean(lloss)\n",
        "        loss_eval.append(avg_loss_eval)\n",
        "        if avg_loss_eval < lowest_loss_eval:\n",
        "            lowest_loss_eval = avg_loss_eval\n",
        "            last_best_result = 0\n",
        "            print(\"Best model found! saving...\")\n",
        "            actual_state = {'optim':opt.state_dict(),'model':model.state_dict(),'epoch':epoch,'loss_train':loss_train,'loss_eval':loss_eval}\n",
        "            torch.save(actual_state,'best_modelmh.pth')\n",
        "        last_best_result += 1\n",
        "        if last_best_result > patience_time:\n",
        "            stop = True\n",
        "        print(\"epoch %d loss_train %4.3f loss_eval %4.3f last_best %d\"%(epoch,loss_train[-1],loss_eval[-1],last_best_result))\n",
        "        epoch += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db0tJUAZtRPk"
      },
      "source": [
        "classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCIxGa6fpi9A"
      },
      "outputs": [],
      "source": [
        "all_preds_fine = []\n",
        "all_labels_fine = []\n",
        "all_preds_coarse = []\n",
        "all_labels_coarse = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader2:\n",
        "        images = batch[\"pixel_values\"].to(device)\n",
        "        labels_fine = batch[\"labelsc\"].to(device)\n",
        "        labels_coarse = batch[\"labelssc\"].to(device)\n",
        "\n",
        "        out_fine, out_coarse = model(images)\n",
        "\n",
        "        preds_fine = out_fine.argmax(dim=1).cpu().numpy()\n",
        "        preds_coarse = out_coarse.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "        all_preds_fine.extend(preds_fine)\n",
        "        all_labels_fine.extend(labels_fine.cpu().numpy())\n",
        "        all_preds_coarse.extend(preds_coarse)\n",
        "        all_labels_coarse.extend(labels_coarse.cpu().numpy())\n",
        "\n",
        "\n",
        "print(classification_report(all_labels_fine, all_preds_fine))\n",
        "print(classification_report(all_labels_coarse, all_preds_coarse))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPqR/aQIK+j5f1cPCkiv5ZZ"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}