{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPLFtmuZBKvJaXFSDyihHmv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"TQEv-uVrYmal","executionInfo":{"status":"ok","timestamp":1762139095524,"user_tz":240,"elapsed":21725,"user":{"displayName":"BRUNO BIAGI DE LIMA PIVETA","userId":"13963231046749467786"}}},"outputs":[],"source":["import torchvision\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import torchvision.transforms as transforms\n","\n","import timm\n","from datasets import load_dataset, DatasetDict\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","\n","from torch import optim\n","import sklearn.metrics as metrics\n","from sklearn.metrics import classification_report"]},{"cell_type":"markdown","source":["Carrega o dataset e o divide em: treino, teste e validação"],"metadata":{"id":"AIbrq4emrQ2K"}},{"cell_type":"code","source":["dataset = load_dataset(\"cifar100\")\n","\n","split = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n","\n","dataset = DatasetDict({\"train\": split[\"train\"], \"val\": split[\"test\"], \"test\": dataset[\"test\"]})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1csgW13hL4bk","executionInfo":{"status":"ok","timestamp":1762139097546,"user_tz":240,"elapsed":2019,"user":{"displayName":"BRUNO BIAGI DE LIMA PIVETA","userId":"13963231046749467786"}},"outputId":"552de034-6848-49f3-dbd4-b6b7fd58d3e8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["Aplica as transformações e argumentações no datase"],"metadata":{"id":"4p0sB4zGrlZZ"}},{"cell_type":"code","source":["transform_224 = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])"],"metadata":{"id":"eSWnerjuZOW0","executionInfo":{"status":"ok","timestamp":1762139097554,"user_tz":240,"elapsed":6,"user":{"displayName":"BRUNO BIAGI DE LIMA PIVETA","userId":"13963231046749467786"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def transform_batch(example_batch):\n","    example_batch[\"pixel_values\"] = [transform_224(img.convert(\"RGB\")) for img in example_batch[\"img\"]]\n","    example_batch[\"labelsc\"] = example_batch[\"fine_label\"]\n","    example_batch[\"labelssc\"] = example_batch[\"coarse_label\"]\n","    del example_batch[\"img\"]\n","    return example_batch\n","\n","dataset[\"train\"].set_transform(transform_batch)\n","dataset[\"val\"].set_transform(transform_batch)\n","dataset[\"test\"].set_transform(transform_batch)"],"metadata":{"id":"cqXfkiUbZfl-","executionInfo":{"status":"ok","timestamp":1762139097583,"user_tz":240,"elapsed":23,"user":{"displayName":"BRUNO BIAGI DE LIMA PIVETA","userId":"13963231046749467786"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["train_loader = DataLoader(dataset[\"train\"], batch_size=128, shuffle=True, num_workers=2)\n","val_loader = DataLoader(dataset[\"val\"], batch_size=128, shuffle=False, num_workers=2)\n","test_loader = DataLoader(dataset[\"test\"], batch_size=128, shuffle=False, num_workers=2)"],"metadata":{"id":"FidBDT30alJQ","executionInfo":{"status":"ok","timestamp":1762139097600,"user_tz":240,"elapsed":1,"user":{"displayName":"BRUNO BIAGI DE LIMA PIVETA","userId":"13963231046749467786"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"],"metadata":{"id":"o_k23GioFvvF","executionInfo":{"status":"ok","timestamp":1762139097620,"user_tz":240,"elapsed":14,"user":{"displayName":"BRUNO BIAGI DE LIMA PIVETA","userId":"13963231046749467786"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["modelo 100 classes"],"metadata":{"id":"JgAaSMohrruF"}},{"cell_type":"code","source":["model = timm.create_model('mobilenetv3_small_100', pretrained=True, num_classes=100)\n","model.to(device)\n","\n","loss_train = []\n","loss_eval  = []\n","patience_time = 15\n","criterion = nn.CrossEntropyLoss()\n","opt = optim.AdamW(model.parameters(),lr=0.01)\n","epochs = 100\n","epoch = 0"],"metadata":{"id":"MN4aR7mLdOHo","executionInfo":{"status":"ok","timestamp":1762139097799,"user_tz":240,"elapsed":174,"user":{"displayName":"BRUNO BIAGI DE LIMA PIVETA","userId":"13963231046749467786"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Treino"],"metadata":{"id":"7b97pyIAtAlk"}},{"cell_type":"code","source":["stop = False\n","lowest_loss_eval = 10000\n","last_best_result = 0\n","\n","while (not stop):\n","    model.train()\n","    lloss = []\n","    for batch in train_loader:\n","        images = batch[\"pixel_values\"].to(device)\n","        labels = batch[\"labelsc\"].to(device)\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        pred = model(images)\n","        closs = criterion(pred,labels)\n","        closs.backward()\n","        opt.step()\n","        opt.zero_grad()\n","        lloss.append(closs.item())\n","    loss_train.append(np.mean(lloss))\n","    lloss = []\n","    model.eval()\n","    lres = []\n","    lbtrue = []\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            images = batch[\"pixel_values\"].to(device)\n","            labels = batch[\"labelsc\"].to(device)\n","            images = images.to(device)\n","\n","            pred = model(images)\n","            closs = criterion(pred.cpu(),labels)\n","            lloss.append(closs.item())\n","            res  = pred.argmax(dim=1).cpu().tolist()\n","            lres += res\n","            lbtrue += labels\n","        avg_loss_eval = np.mean(lloss)\n","        loss_eval.append(avg_loss_eval)\n","        if avg_loss_eval < lowest_loss_eval:\n","            lowest_loss_eval = avg_loss_eval\n","            last_best_result = 0\n","            print(\"Best model found! saving...\")\n","            actual_state = {'optim':opt.state_dict(),'model':model.state_dict(),'epoch':epoch,'loss_train':loss_train,'loss_eval':loss_eval}\n","            torch.save(actual_state,'best_modelc.pth')\n","        last_best_result += 1\n","        if last_best_result > patience_time:\n","            stop = True\n","        print(\"epoch %d loss_train %4.3f loss_eval %4.3f last_best %d\"%(epoch,loss_train[-1],loss_eval[-1],last_best_result))\n","        epoch += 1"],"metadata":{"id":"qzBlyizHdeDm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["classification report"],"metadata":{"id":"rW7OafpXtC_h"}},{"cell_type":"code","source":["all_preds = []\n","all_labels = []\n","\n","with torch.no_grad():\n","    for batch in test_loader:\n","        images = batch[\"pixel_values\"].to(device)\n","        labels = batch[\"labelsc\"].to(device)\n","\n","        outputs = model(images)\n","        preds = outputs.argmax(dim=1)\n","\n","        all_preds.extend(preds.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","\n","\n","print(classification_report(all_labels, all_preds))"],"metadata":{"id":"Nv1uMXvyozDI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["modelo 20 super-classes"],"metadata":{"id":"gdBtLYRArzfT"}},{"cell_type":"code","source":["model = timm.create_model('mobilenetv3_small_100', pretrained=True, num_classes=20)\n","model.to(device)\n","\n","loss_train = []\n","loss_eval  = []\n","patience_time = 15\n","criterion = nn.CrossEntropyLoss()\n","opt = optim.AdamW(model.parameters(),lr=0.01)\n","epochs = 100\n","epoch = 0"],"metadata":{"id":"s4OqQ9fcgHbN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Treino"],"metadata":{"id":"1XYgi4ZVtHrA"}},{"cell_type":"code","source":["stop = False\n","lowest_loss_eval = 10000\n","last_best_result = 0\n","\n","while (not stop):\n","    model.train()\n","    lloss = []\n","    for batch in train_loader:\n","        images = batch[\"pixel_values\"].to(device)\n","        labels = batch[\"labelssc\"].to(device)\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        pred = model(images)\n","        closs = criterion(pred,labels)\n","        closs.backward()\n","        opt.step()\n","        opt.zero_grad()\n","        lloss.append(closs.item())\n","    loss_train.append(np.mean(lloss))\n","    lloss = []\n","    model.eval()\n","    lres = []\n","    lbtrue = []\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            images = batch[\"pixel_values\"].to(device)\n","            labels = batch[\"labelssc\"].to(device)\n","            images = images.to(device)\n","\n","            pred = model(images)\n","            closs = criterion(pred.cpu(),labels)\n","            lloss.append(closs.item())\n","            res  = pred.argmax(dim=1).cpu().tolist()\n","            lres += res\n","            lbtrue += labels\n","        avg_loss_eval = np.mean(lloss)\n","        loss_eval.append(avg_loss_eval)\n","        if avg_loss_eval < lowest_loss_eval:\n","            lowest_loss_eval = avg_loss_eval\n","            last_best_result = 0\n","            print(\"Best model found! saving...\")\n","            actual_state = {'optim':opt.state_dict(),'model':model.state_dict(),'epoch':epoch,'loss_train':loss_train,'loss_eval':loss_eval}\n","            torch.save(actual_state,'best_modelsc.pth')\n","        last_best_result += 1\n","        if last_best_result > patience_time:\n","            stop = True\n","        print(\"epoch %d loss_train %4.3f loss_eval %4.3f last_best %d\"%(epoch,loss_train[-1],loss_eval[-1],last_best_result))\n","        epoch += 1"],"metadata":{"id":"son1kAPtgDlN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["classification report"],"metadata":{"id":"G7TNkqPstKxv"}},{"cell_type":"code","source":["all_preds = []\n","all_labels = []\n","\n","with torch.no_grad():\n","    for batch in test_loader:\n","        images = batch[\"pixel_values\"].to(device)\n","        labels = batch[\"labelssc\"].to(device)\n","\n","        outputs = model(images)\n","        preds = outputs.argmax(dim=1)\n","\n","        all_preds.extend(preds.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","\n","\n","print(classification_report(all_labels, all_preds))"],"metadata":{"id":"6t0OvCnpphb3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["modelo multihead"],"metadata":{"id":"AoLEx1_Zr3pC"}},{"cell_type":"code","source":["class MultiHeadMobileNetV3(nn.Module):\n","    def __init__(self, pretrained=True, num_classes_fine=100, num_classes_coarse=10):\n","        super().__init__()\n","\n","        base_model = timm.create_model(\"mobilenetv3_small_100\", pretrained=True, num_classes=0)\n","\n","        self.backbone = base_model\n","\n","\n","        in_features = 1024\n","        self.head_fine = nn.Linear(in_features, num_classes_fine)\n","        self.head_coarse = nn.Linear(in_features, num_classes_coarse)\n","\n","    def forward(self, x):\n","        feats = self.backbone(x)\n","        out_fine = self.head_fine(feats)\n","        out_coarse = self.head_coarse(feats)\n","        return out_fine, out_coarse"],"metadata":{"id":"oLIJ88H7hoBg","executionInfo":{"status":"ok","timestamp":1762137171050,"user_tz":240,"elapsed":2,"user":{"displayName":"BRUNO BIAGI DE LIMA PIVETA","userId":"13963231046749467786"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["model = MultiHeadMobileNetV3()\n","model.to(device)\n","\n","loss_train = []\n","loss_eval  = []\n","patience_time = 15\n","criterion = nn.CrossEntropyLoss()\n","opt = optim.AdamW(model.parameters(),lr=0.01)\n","epochs = 100\n","epoch = 0"],"metadata":{"id":"W_nJCOy6j90N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Treino"],"metadata":{"id":"N1idPUd8tPeQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stop = False\n","lowest_loss_eval = 10000\n","last_best_result = 0\n","\n","while (not stop):\n","    model.train()\n","    lloss = []\n","    for batch in train_loader:\n","        images = batch[\"pixel_values\"].to(device)\n","        labels_fine = batch[\"labelsc\"].to(device)\n","        labels_coarse = batch[\"labelssc\"].to(device)\n","        images = images.to(device)\n","        labelsc = labels.to(device)\n","        pred_fine, pred_coarse = model(images)\n","        loss_fine = criterion(pred_fine, labels_fine)\n","        loss_coarse = criterion(pred_coarse, labels_coarse)\n","        loss = 0.7 * loss_fine + 0.3 * loss_coarse\n","        loss.backward()\n","        opt.step()\n","        opt.zero_grad()\n","        lloss.append(loss.item())\n","    loss_train.append(np.mean(lloss))\n","    lloss = []\n","    model.eval()\n","    lres = []\n","    lbtrue = []\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            images = batch[\"pixel_values\"].to(device)\n","            labels_fine = batch[\"labelsc\"].to(device)\n","            labels_coarse = batch[\"labelssc\"].to(device)\n","            images = images.to(device)\n","\n","            pred_fine, pred_coarse = model(images)\n","            loss_fine = criterion(pred_fine.cpu(), labels_fine)\n","            loss_coarse = criterion(pred_coarse.cpu(), labels_coarse)\n","            loss = 0.7 * loss_fine + 0.3 * loss_coarse\n","            lloss.append(loss.item())\n","            res  = pred.argmax(dim=1).cpu().tolist()\n","            lres += res\n","            lbtrue += labels\n","        avg_loss_eval = np.mean(lloss)\n","        loss_eval.append(avg_loss_eval)\n","        if avg_loss_eval < lowest_loss_eval:\n","            lowest_loss_eval = avg_loss_eval\n","            last_best_result = 0\n","            print(\"Best model found! saving...\")\n","            actual_state = {'optim':opt.state_dict(),'model':model.state_dict(),'epoch':epoch,'loss_train':loss_train,'loss_eval':loss_eval}\n","            torch.save(actual_state,'best_modelsc.pth')\n","        last_best_result += 1\n","        if last_best_result > patience_time:\n","            stop = True\n","        print(\"epoch %d loss_train %4.3f loss_eval %4.3f last_best %d\"%(epoch,loss_train[-1],loss_eval[-1],last_best_result))\n","        epoch += 1"],"metadata":{"id":"xiMaQmy5kCt5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["classification report"],"metadata":{"id":"db0tJUAZtRPk"}},{"cell_type":"code","source":["all_preds_fine = []\n","all_labels_fine = []\n","all_preds_coarse = []\n","all_labels_coarse = []\n","with torch.no_grad():\n","    for batch in test_loader:\n","        images = batch[\"pixel_values\"].to(device)\n","        labels_fine = batch[\"labelsc\"].to(device)\n","        labels_coarse = batch[\"labelssc\"].to(device)\n","\n","        out_fine, out_coarse = model(images)\n","\n","        preds_fine = out_fine.argmax(dim=1).cpu().numpy()\n","        preds_coarse = out_coarse.argmax(dim=1).cpu().numpy()\n","\n","        all_preds_fine.extend(preds_fine)\n","        all_labels_fine.extend(labels_fine.cpu().numpy())\n","        all_preds_coarse.extend(preds_coarse)\n","        all_labels_coarse.extend(labels_coarse.cpu().numpy())\n","\n","\n","print(classification_report(all_labels, all_preds))"],"metadata":{"id":"OCIxGa6fpi9A"},"execution_count":null,"outputs":[]}]}